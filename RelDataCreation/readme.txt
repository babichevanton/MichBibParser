В PyCharm проекте RelDataCreation 3 конфигурации запуска. Нужна Test Data Gen. Записи берутся из файла data/samples.json и для каждой происходит сопоставление токенов текста и меток атрибутов.

Формат одной записи: [текст записи, словарь атрибутов записи]

Сопоставление меток 1 записи ищется следующим образом:
1) Для каждой метки атрибута записи запоминается длина значения атрибута в токенах - window_size.
2) Далее:
	а) В тексте записи выбирается window_size подряд идущих токенов. Необходимо перебрать все такие последовательности токенов. Каждая последовательность - это список токенов текста записи.
	б) Ищутся 2 характеристики. Первая - число элементов последовательности, являющихся началом токенов значения атрибута (один элемент последовательнояти явл. началом не более одного токена значения атрибута). Вторая- расстояние Левенштейна между конкатенацией элементов последовательности и значением атрибута.
	в) Запоминается последовательность с наибольшей первой характеристикой и (в случае равенства первой с таковой для другой последовательности) наименьшей второй. То есть выбиреается минимально отличающийся от значения атрибута набор токенов, где есть максимальное число префиксов токенов значения атрибута.
	Зачем? - Расстояние Левенштейна плохо обрабатывает инициалы авторов и плохо справляется с ситуациями, когда токены переставлены местами. Предпологаю, что такое вот хитрое 'пересечение' множеств токенов сможет уменьшить влияние инициалов на точность.
3) Процедура повторяется для размеров окон от window_size до 1

Беглая проверка показала, что инициалы стали обрабатываться лучше.
Есть проблема, заметил при проверке. Если в тексте записи токен написан с ошибкой/опечаткой, то токен скорее всего не сопоставится. Возможное решение -  использовать вместо проверки на префикс максимальный общий префикс каждой пары и отсекать его по порогу. Но, на мой взгляд, это трудно, и я не знаю, стоит ли оно того.


ТРЕНИРОВКА И ПРОВЕРКА ТОЧНОСТИ РАБОТЫ.

Чтобы проверить, что алгоритм выполняет работу до конца и переваривает большой объем тренировочных данных, натренировал классификаторы на 7 тысячах записей из обучающих данных. Сами данные не трогал (для них все еще актуальна проблема грязных сопоставлений, отмеченная "критичской")
При построении векторов из тренировочных данных для классификаторов заметил баги, связанные с кодировкой строк (при переходе от юникода в некоторых местах вылетают исключнения от аски-кодека). Исправил несколько багов из них, если все равно кодек ругается, то запись не рассматриваю. В итоге из 7 тысяч записей с ошибкой обработались около 20, их влияние несущественно. СВМ тренировался долго (~10 минут), а вот мультиномиальная логистическая регрессия (если она, конечно, все же мультиномиальная) натренировалась секунд за 10, причем на 200000 векторов. По-моему, это очень странно, не знаю, в чем причина. Сам классификатор создается в методе __init__() класса PostExplorer (файл extractor.py, поле attr_classifier). Посмотрите, пожалуйста, я наверняка что-то не так делаю.
Далее попробовал обработать алгоритмом 1 входную запись. Обработка шла очень долго, больше получаса, и результаты сопоставления таковы:
1) на 1 шаге найдена схема поста
пост:
PAOLA INVERARDI AND ALEX WOLF. FORMAL SPECICATION AND ANALYSIS OF SOFTWARE ARCHITECTURES USING THE CHEM- ICAL, ABSTRACT MACHINE MODEL. IEEE TRANSACTIONS ON SOFTWARE ENGINEERING, 1995. TO APPEAR.
схема:
     publisher
     author PETER J. ANGELINE AND GREGORY M. SAUNDERS AND JORDAN B. POLLACK
     year 
     pages 
     title AN EVOLUTIONARY ALGORITHM THAT CONSTRUCTS RECURRENT NEURAL NETWORKS
Как видно, уже ничего общего.
2) на 2 шаге почему-то  все токены были сопоставлены либо автору, либо названию. Тут трудно судить о результатах, так как не понятно, классификатор мультиномиальный или нет.
В целом, это всего лишь 1 запись, так что о точности работы метода пока судить сложно.
Результаты складываются в файл res.json в виде списка пар.